{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_gen_GAN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPj9LBRUo2P35DXNJCFEgm2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcelAnd02/MachineLearning/blob/master/Text_gen_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1bMKY1XkPya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import re\n",
        "import random\n",
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_ojVtWalA9C",
        "colab_type": "code",
        "outputId": "af417bf1-a520-48ae-8d10-b0738bf74b9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3w4CqQdlNdZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_data = pd.read_csv('/content/drive/My Drive/Colab_Notebooks/NLP_Project/PoetryFoundationData.csv')\n",
        "dataset = raw_data.Poem.str.lower().values.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyRjLfAxlWYj",
        "colab_type": "code",
        "outputId": "75453688-ca0d-47f8-912b-0c7581e5ab6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "print(dataset[35])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r\r\n",
            "in florida a giant hamster lays in bed worrying about its future\r\r\n",
            "the hamster has bad eyesight\r\r\n",
            "and many other problems\r\r\n",
            "later that night the hamster drives its car around\r\r\n",
            "listening to sad music; the master lightly drums its paws on the steering wheel\r\r\n",
            "the hamster is alone\r\r\n",
            "but not for long: at home three waffle friends wait\r\r\n",
            "cooling inside a countertop oven in the kitchen\r\r\n",
            " \r\r\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2glN7WepqqL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = list(map(lambda x: re.findall(f\"[\\w]+|[.,'?!{chr(8217)}]\", x), dataset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_wC-4NNmg3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_unique = 2000 #max number of unique words in model's vocab\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(filters = \"\")\n",
        "tokenizer.fit_on_texts(dataset)\n",
        "dataset_tokenized = tokenizer.texts_to_sequences(dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05eDrCSQpW9f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chain_len = 20\n",
        "X = []\n",
        "def filter_dataset():\n",
        "  for ind, ex in enumerate(dataset_tokenized):\n",
        "    for beg in range(0, len(ex) - chain_len):\n",
        "      if np.max(ex[beg : beg + chain_len]) <= num_unique:\n",
        "        X.append(dataset[ind][beg : beg + chain_len])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A36I8hVT2Pok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filter_dataset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xt1t-pdCqCmh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_lng = 20000\n",
        "random.shuffle(X)\n",
        "X = X[0 : input_lng]\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(filters = \"\")\n",
        "tokenizer.fit_on_texts(X)\n",
        "X = tokenizer.texts_to_sequences(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayZftDYzskdt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.asarray(X)\n",
        "X = keras.utils.to_categorical(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKJCrYSSsoKB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6779116f-f738-405a-8431-a56e65fbc5af"
      },
      "source": [
        "print(X.shape)\n",
        "num_unique = X.shape[2]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20000, 20, 1999)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgJTcWPIkrbn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4758fd1e-2ebd-4ff4-e54e-c0a095fa2f77"
      },
      "source": [
        "tokenizer.sequences_to_texts([[127]])[0]"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'yet'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKVfIZkZPsjl",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jaxq8r45Pvsd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "compact_size = 300\n",
        "encoder = keras.models.Sequential(\n",
        "    [\n",
        "     keras.layers.LSTM(128, input_shape = (chain_len, num_unique)),\n",
        "     keras.layers.Dense(512, activation = \"selu\"),\n",
        "     keras.layers.Dense(compact_size, activation = \"selu\"),\n",
        "    ]\n",
        ")\n",
        "decoder = keras.models.Sequential(\n",
        "    [\n",
        "     keras.layers.Dense(512, activation = \"selu\", input_shape = [compact_size]),\n",
        "     keras.layers.RepeatVector(chain_len),\n",
        "     keras.layers.LSTM(128, return_sequences = True),\n",
        "     keras.layers.TimeDistributed(keras.layers.Dense(num_unique)),\n",
        "    ]\n",
        ")\n",
        "AutoEncoder = keras.models.Sequential([encoder, decoder])\n",
        "AutoEncoder.compile(optimizer = \"adam\", loss = \"mse\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjCg5DAFYpZZ",
        "colab_type": "code",
        "outputId": "5dfd84ae-3c58-47a8-cdd7-fc800e352c6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "AutoEncoder.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential_3 (Sequential)    (None, 300)               1309484   \n",
            "_________________________________________________________________\n",
            "sequential_4 (Sequential)    (None, 20, 1999)          740175    \n",
            "=================================================================\n",
            "Total params: 2,049,659\n",
            "Trainable params: 2,049,659\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFHn5jG9aKUw",
        "colab_type": "code",
        "outputId": "aca8ebc7-9566-4b79-fed8-9013774b4649",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "AutoEncoder.fit(X, X, batch_size = 128, epochs = 150)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.9855e-04\n",
            "Epoch 2/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.9074e-04\n",
            "Epoch 3/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.8704e-04\n",
            "Epoch 4/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.8487e-04\n",
            "Epoch 5/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.8359e-04\n",
            "Epoch 6/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.8253e-04\n",
            "Epoch 7/150\n",
            "157/157 [==============================] - 4s 29ms/step - loss: 4.8142e-04\n",
            "Epoch 8/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.8061e-04\n",
            "Epoch 9/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.7994e-04\n",
            "Epoch 10/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.7937e-04\n",
            "Epoch 11/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.7893e-04\n",
            "Epoch 12/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.7835e-04\n",
            "Epoch 13/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.7791e-04\n",
            "Epoch 14/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.7728e-04\n",
            "Epoch 15/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.7624e-04\n",
            "Epoch 16/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.7588e-04\n",
            "Epoch 17/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.7558e-04\n",
            "Epoch 18/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.7509e-04\n",
            "Epoch 19/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.7433e-04\n",
            "Epoch 20/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.7398e-04\n",
            "Epoch 21/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.7376e-04\n",
            "Epoch 22/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.7339e-04\n",
            "Epoch 23/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.7285e-04\n",
            "Epoch 24/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.7243e-04\n",
            "Epoch 25/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.7203e-04\n",
            "Epoch 26/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.7175e-04\n",
            "Epoch 27/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.7130e-04\n",
            "Epoch 28/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.7091e-04\n",
            "Epoch 29/150\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 4.7067e-04\n",
            "Epoch 30/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.7043e-04\n",
            "Epoch 31/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.7035e-04\n",
            "Epoch 32/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.6976e-04\n",
            "Epoch 33/150\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 4.6938e-04\n",
            "Epoch 34/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.6904e-04\n",
            "Epoch 35/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.6841e-04\n",
            "Epoch 36/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.6787e-04\n",
            "Epoch 37/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.6748e-04\n",
            "Epoch 38/150\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 4.6709e-04\n",
            "Epoch 39/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.6660e-04\n",
            "Epoch 40/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.6623e-04\n",
            "Epoch 41/150\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 4.6601e-04\n",
            "Epoch 42/150\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 4.6583e-04\n",
            "Epoch 43/150\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 4.6562e-04\n",
            "Epoch 44/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.6543e-04\n",
            "Epoch 45/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.6507e-04\n",
            "Epoch 46/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.6477e-04\n",
            "Epoch 47/150\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 4.6437e-04\n",
            "Epoch 48/150\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 4.6388e-04\n",
            "Epoch 49/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.6342e-04\n",
            "Epoch 50/150\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 4.6295e-04\n",
            "Epoch 51/150\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 4.6229e-04\n",
            "Epoch 52/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.6180e-04\n",
            "Epoch 53/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.6096e-04\n",
            "Epoch 54/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.6045e-04\n",
            "Epoch 55/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.5999e-04\n",
            "Epoch 56/150\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 4.5954e-04\n",
            "Epoch 57/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.5906e-04\n",
            "Epoch 58/150\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 4.5848e-04\n",
            "Epoch 59/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.5760e-04\n",
            "Epoch 60/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.5674e-04\n",
            "Epoch 61/150\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 4.5598e-04\n",
            "Epoch 62/150\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 4.5536e-04\n",
            "Epoch 63/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.5480e-04\n",
            "Epoch 64/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.5405e-04\n",
            "Epoch 65/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.5330e-04\n",
            "Epoch 66/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.5222e-04\n",
            "Epoch 67/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.5101e-04\n",
            "Epoch 68/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.4948e-04\n",
            "Epoch 69/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.4783e-04\n",
            "Epoch 70/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.4626e-04\n",
            "Epoch 71/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.4499e-04\n",
            "Epoch 72/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.4390e-04\n",
            "Epoch 73/150\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 4.4295e-04\n",
            "Epoch 74/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.4172e-04\n",
            "Epoch 75/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.4101e-04\n",
            "Epoch 76/150\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 4.3965e-04\n",
            "Epoch 77/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.3858e-04\n",
            "Epoch 78/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.3738e-04\n",
            "Epoch 79/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.3621e-04\n",
            "Epoch 80/150\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 4.3417e-04\n",
            "Epoch 81/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.3231e-04\n",
            "Epoch 82/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.3037e-04\n",
            "Epoch 83/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.2869e-04\n",
            "Epoch 84/150\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 4.2735e-04\n",
            "Epoch 85/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.2662e-04\n",
            "Epoch 86/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.2510e-04\n",
            "Epoch 87/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.2407e-04\n",
            "Epoch 88/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.2320e-04\n",
            "Epoch 89/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.2241e-04\n",
            "Epoch 90/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.2353e-04\n",
            "Epoch 91/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.2153e-04\n",
            "Epoch 92/150\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 4.1988e-04\n",
            "Epoch 93/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.1852e-04\n",
            "Epoch 94/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.1822e-04\n",
            "Epoch 95/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.1731e-04\n",
            "Epoch 96/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.1620e-04\n",
            "Epoch 97/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.1493e-04\n",
            "Epoch 98/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.1279e-04\n",
            "Epoch 99/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.1282e-04\n",
            "Epoch 100/150\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 4.1125e-04\n",
            "Epoch 101/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.1038e-04\n",
            "Epoch 102/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.0894e-04\n",
            "Epoch 103/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.0897e-04\n",
            "Epoch 104/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.0731e-04\n",
            "Epoch 105/150\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 4.0435e-04\n",
            "Epoch 106/150\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 4.0418e-04\n",
            "Epoch 107/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.0370e-04\n",
            "Epoch 108/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 4.0171e-04\n",
            "Epoch 109/150\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 4.0229e-04\n",
            "Epoch 110/150\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 4.0358e-04\n",
            "Epoch 111/150\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 3.9980e-04\n",
            "Epoch 112/150\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 3.9988e-04\n",
            "Epoch 113/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 3.9617e-04\n",
            "Epoch 114/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 3.9528e-04\n",
            "Epoch 115/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 3.9419e-04\n",
            "Epoch 116/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 3.9231e-04\n",
            "Epoch 117/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 3.9177e-04\n",
            "Epoch 118/150\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 3.9314e-04\n",
            "Epoch 119/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 3.9077e-04\n",
            "Epoch 120/150\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 3.8956e-04\n",
            "Epoch 121/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 3.8680e-04\n",
            "Epoch 122/150\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 3.8681e-04\n",
            "Epoch 123/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 3.8982e-04\n",
            "Epoch 124/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 3.8651e-04\n",
            "Epoch 125/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 3.8410e-04\n",
            "Epoch 126/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 3.9266e-04\n",
            "Epoch 127/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 3.8595e-04\n",
            "Epoch 128/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 3.8536e-04\n",
            "Epoch 129/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 3.8283e-04\n",
            "Epoch 130/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 3.8077e-04\n",
            "Epoch 131/150\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 3.8697e-04\n",
            "Epoch 132/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 3.8333e-04\n",
            "Epoch 133/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 3.7817e-04\n",
            "Epoch 134/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 3.7727e-04\n",
            "Epoch 135/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 3.7640e-04\n",
            "Epoch 136/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 3.7527e-04\n",
            "Epoch 137/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 3.7663e-04\n",
            "Epoch 138/150\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 3.7502e-04\n",
            "Epoch 139/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 3.7950e-04\n",
            "Epoch 140/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 3.8211e-04\n",
            "Epoch 141/150\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 3.7451e-04\n",
            "Epoch 142/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 3.7521e-04\n",
            "Epoch 143/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 3.7279e-04\n",
            "Epoch 144/150\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 3.7000e-04\n",
            "Epoch 145/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 3.6803e-04\n",
            "Epoch 146/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 3.6947e-04\n",
            "Epoch 147/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 3.6632e-04\n",
            "Epoch 148/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 3.6750e-04\n",
            "Epoch 149/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 3.6694e-04\n",
            "Epoch 150/150\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 3.6609e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f46f15170f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60VGB6TVbF1p",
        "colab_type": "code",
        "outputId": "d2ab9dbe-e78e-45bf-fef6-80c95ee1ddfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Xc = X[0].reshape((1, X[0].shape[0], X[0].shape[1]))\n",
        "print(AutoEncoder.predict(Xc)[0].shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20, 1999)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKoQ9hsWenTe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_text(vec):\n",
        "  pred = []\n",
        "  for word in vec:\n",
        "    pos = np.argmax(word)\n",
        "    if pos == 0:\n",
        "      continue\n",
        "    pred.append(tokenizer.sequences_to_texts([[pos]])[0])\n",
        "  return pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpimQvTQ1mpr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "6ce9c521-98db-41a5-f488-907eb5ec706d"
      },
      "source": [
        "ind = 5\n",
        "pred = AutoEncoder.predict(X[ind].reshape((1, X[ind].shape[0], X[ind].shape[1])))[0]\n",
        "print(build_text(pred))\n",
        "print(build_text(X[ind]))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['the', 'you', 'you', 'you', 'you', 'you', 'you', 'you', 'you', 'you', '.', 'you', 'a', 'a', 'a', 'a', '’', 's', 'a', 'a']\n",
            "['the', 'food', 'they', 'keep', 'on', 'giving', 'you', 'makes', 'you', 'sick', '.', 'this', 'hunger', 'is', 'a', 'moment', '’', 's', 'vision', 'that']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}